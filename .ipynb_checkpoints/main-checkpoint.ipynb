{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network from Kell, Yamins, Shook, Norman-Haignere, McDermott, 2018\n",
    "\n",
    "This notebook shows how to create a tensorflow graph for the network with the weights and biases used in <a href=\"https://www.cell.com/neuron/fulltext/S0896-6273(18)30250-2\">Kell et al., 2018</a>. This notebook also gives an example of how to pass a sound into the network.\n",
    "\n",
    "\n",
    "### Note on network input\n",
    "\n",
    "The input to the network is a \"cochleagram\", a time-frequency decomposition of a sound that is similar to a spectrogram. Below we provide examples of how to pass a pre-computed cochleagram into the network, as well as how to compute the cochleagram for an example wav and then pass that cochleagram to the network.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Most of the dependencies to run this are relatively standard. However, please note the following:\n",
    "- This notebook was tested and run with version 1.5.0 of `tensorflow`. It was not tested with other versions.\n",
    "- `pycochleagram` is a module to generate cochleagrams to pass sounds into the network, which can be found <a href=\"https://github.com/mcdermottLab/pycochleagram\">here</a>.\n",
    "- `PIL` is the Python Image Library.\n",
    "\n",
    "### Contact\n",
    "If you have any questions, please contact Alex Kell. Email: < first_name >< last_name >@mit.edu.\n",
    "\n",
    "Thanks, and enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import sys\n",
    "sys.path.append('./network/')\n",
    "from branched_network_class import branched_network\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib as plt \n",
    "%pylab inline\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the following to run demo_from_wav()\n",
    "from pycochleagram import cochleagram as cgram \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some helper functions\n",
    "def resample(example, new_size):\n",
    "    im = Image.fromarray(example)\n",
    "    resized_image = im.resize(new_size, resample=Image.ANTIALIAS)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "def plot_cochleagram(cochleagram, title): \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.matshow(cochleagram.reshape(256,256), origin='lower',cmap=plt.cm.Blues, fignum=False, aspect='auto')\n",
    "    plt.yticks([]); plt.xticks([]); plt.title(title); \n",
    "    \n",
    "def play_wav(wav_f, sr, title):   \n",
    "    print title+':'\n",
    "    ipd.display(ipd.Audio(wav_f, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 small\n",
      "78 call\n",
      "139 things\n",
      "219 cheese\n",
      "241 store\n",
      "263 need\n",
      "396 these\n",
      "397 also\n",
      "514 into\n",
      "585 fresh\n"
     ]
    }
   ],
   "source": [
    "word_key = np.load('./demo_stim/logits_to_word_key.npy') # load logits to word key\n",
    "allowed_words = [\n",
    "    'also',\n",
    "    'call',\n",
    "    'cheese',\n",
    "    'fresh',\n",
    "    'into',\n",
    "    'need',\n",
    "    'small',\n",
    "    'store',\n",
    "    'these',\n",
    "    'things',\n",
    "]\n",
    "\n",
    "for i, word in enumerate(word_key):\n",
    "    if word in allowed_words:\n",
    "        print i, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (211,4) (211,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7c02e00f7ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Speech Example ... \\n clean speech, actual label: Increasingly, predicted_label: \"\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdemo_from_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/cantonese/cantonese1/also.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-7c02e00f7ef6>\u001b[0m in \u001b[0;36mdemo_from_wav\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# note the sampling rate is 16000hz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     play_wav(wav_f, sr, filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mc_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cochleagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnet_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_gram\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9dc0532a1b08>\u001b[0m in \u001b[0;36mgenerate_cochleagram\u001b[0;34m(wav_f, sr, title)\u001b[0m\n\u001b[1;32m     10\u001b[0m     c_gram = cgram.cochleagram(wav_f, sr, n, low_lim, hi_lim, \n\u001b[1;32m     11\u001b[0m                                \u001b[0msample_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                nonlinearity, fft_mode, ret_mode, strict)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# rescale to [0,255]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davidlee/dev/kelletal2018/venv/local/lib/python2.7/site-packages/pycochleagram-0.1-py2.7.egg/pycochleagram/cochleagram.pyc\u001b[0m in \u001b[0;36mcochleagram\u001b[0;34m(signal, sr, n, low_lim, hi_lim, sample_factor, padding_size, downsample, nonlinearity, fft_mode, ret_mode, strict, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'envs'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mret_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m       temp_sb = sb.generate_subband_envelopes_fast(temp_signal_flat, filts,\n\u001b[0;32m--> 158\u001b[0;31m           padding_size=padding_size, fft_mode=fft_mode, debug_ret_all=ret_all_sb)\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mret_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'subband'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m       temp_sb = sb.generate_subbands(temp_signal_flat, filts, padding_size=padding_size,\n",
      "\u001b[0;32m/home/davidlee/dev/kelletal2018/venv/local/lib/python2.7/site-packages/pycochleagram-0.1-py2.7.egg/pycochleagram/subband.pyc\u001b[0m in \u001b[0;36mgenerate_subband_envelopes_fast\u001b[0;34m(signal, filters, padding_size, fft_mode, debug_ret_all)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0msubbands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfft_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0manalytic_subbands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfhilbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfft_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m   \u001b[0msubband_envelopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytic_subbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davidlee/dev/kelletal2018/venv/local/lib/python2.7/site-packages/pycochleagram-0.1-py2.7.egg/pycochleagram/utils.pyc\u001b[0m in \u001b[0;36mfhilbert\u001b[0;34m(a, axis, mode, ifft_params)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m   \u001b[0mah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m  \u001b[0;31m# apply hilbert transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifft_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (211,4) (211,) "
     ]
    }
   ],
   "source": [
    "def demo_from_wav(filename):\n",
    "    tf.reset_default_graph()\n",
    "    net_object = branched_network()\n",
    "    word_key = np.load('./demo_stim/logits_to_word_key.npy') # load logits to word key\n",
    "    music_key = np.load('./demo_stim/logits_to_genre_key.npy') # load logits to word key \n",
    "    \n",
    "    \n",
    "    # generate cochleagram, then pass cochleagram through network and get logits for word branch\n",
    "    \n",
    "    ## Speech examples\n",
    "    \n",
    "    # example 1:\n",
    "    sr, wav_f = wav.read(filename) # note the sampling rate is 16000hz.\n",
    "#     play_wav(wav_f, sr, filename)\n",
    "    c_gram = generate_cochleagram(wav_f, sr, filename)\n",
    "    logits = net_object.session.run(net_object.word_logits, feed_dict={net_object.x: c_gram})\n",
    "    prediction = word_key[np.argmax(logits, axis=1)]\n",
    "    print \"Speech Example ... \\n clean speech, actual label: Increasingly, predicted_label: \" \\\n",
    "        + prediction[0] +'\\n'\n",
    "    \n",
    "demo_from_wav('./data/cantonese/cantonese1/also.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file\n",
      "16000\n",
      "Generating cochleagram\n"
     ]
    }
   ],
   "source": [
    "def generate_cochleagram(filename):\n",
    "    # define parameters\n",
    "    print \"Loading file\"\n",
    "\n",
    "    wav_f, sr = librosa.core.load(filename, sr=16000) # note the sampling rate is 16000hz.\n",
    "    print sr\n",
    "    n = 50\n",
    "    low_lim, hi_lim = 20, 8000\n",
    "    sample_factor, pad_factor, downsample = 4, 2, 200\n",
    "    nonlinearity, fft_mode, ret_mode = 'power', 'auto', 'envs'\n",
    "    strict = True\n",
    "    print \"Generating cochleagram\"\n",
    "    # create cochleagram\n",
    "    c_gram = cgram.cochleagram(wav_f, sr, n, low_lim, hi_lim, \n",
    "                               sample_factor, pad_factor, downsample,\n",
    "                               nonlinearity, fft_mode, ret_mode, strict)\n",
    "    print \"Rescaling and reshaping\"\n",
    "\n",
    "    # rescale to [0,255]\n",
    "    c_gram_rescaled =  255*(1-((np.max(c_gram)-c_gram)/np.ptp(c_gram)))\n",
    "    \n",
    "    # reshape to (256,256)\n",
    "    c_gram_reshape_1 = np.reshape(c_gram_rescaled, (211,400))\n",
    "    c_gram_reshape_2 = resample(c_gram_reshape_1,(256,256))\n",
    "    print \"Plotting\"\n",
    "\n",
    "    plot_cochleagram(c_gram_reshape_2, title)\n",
    "\n",
    "    # prepare to run through network -- i.e., flatten it\n",
    "    c_gram_flatten = np.reshape(c_gram_reshape_2, (1, 256*256)) \n",
    "\n",
    "    return c_gram_flatten\n",
    "\n",
    "# filename = './demo_stim/example_1.wav'\n",
    "filename = './data/cantonese/cantonese1/cheese.wav'\n",
    "c_gram = generate_cochleagram(filename)\n",
    "print \"Generated Cochleagram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_generate_cochleagram(wav_f, sr, title):\n",
    "    # define parameters\n",
    "    n, sampling_rate = 50, 16000\n",
    "    low_lim, hi_lim = 20, 8000\n",
    "    sample_factor, pad_factor, downsample = 4, 2, 200\n",
    "    nonlinearity, fft_mode, ret_mode = 'power', 'auto', 'envs'\n",
    "    strict = True\n",
    "\n",
    "    # create cochleagram\n",
    "    c_gram = cgram.cochleagram(wav_f, sr, n, low_lim, hi_lim, \n",
    "                               sample_factor, pad_factor, downsample,\n",
    "                               nonlinearity, fft_mode, ret_mode, strict)\n",
    "    \n",
    "    # rescale to [0,255]\n",
    "    c_gram_rescaled =  255*(1-((np.max(c_gram)-c_gram)/np.ptp(c_gram)))\n",
    "    \n",
    "    # reshape to (256,256)\n",
    "    c_gram_reshape_1 = np.reshape(c_gram_rescaled, (211,400))\n",
    "    c_gram_reshape_2 = resample(c_gram_reshape_1,(256,256))\n",
    "    \n",
    "    plot_cochleagram(c_gram_reshape_2, title)\n",
    "\n",
    "    # prepare to run through network -- i.e., flatten it\n",
    "    c_gram_flatten = np.reshape(c_gram_reshape_2, (1, 256*256)) \n",
    "    \n",
    "    return c_gram_flatten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
